{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73636a5",
   "metadata": {},
   "source": [
    "# <center> Предсказание победителя в Dota 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17dd371",
   "metadata": {},
   "source": [
    "### Начало\n",
    "\n",
    "Посмотрим на готовые признаки и сделаем первую посылку. \n",
    "\n",
    "1. [Описание данных](#Описание-данных)\n",
    "2. [Описание признаков](#Описание-признаков)\n",
    "3. [Наша первая модель](#Наша-первая-модель)\n",
    "4. [Посылка](#Посылка)\n",
    "\n",
    "### Первые шаги на пути в датасайенс\n",
    "\n",
    "5. [Кросс-валидация](#Кросс-валидация)\n",
    "6. [Что есть в json файлах?](#Что-есть-в-json-файлах?)\n",
    "7. [Feature engineering](#Feature-engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Импорты\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10801\n",
    "sns.set_style(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 8\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecd9e7",
   "metadata": {},
   "source": [
    "Часть кода, который я пытался пристроить к делу, но по итогу отмел, закомментирован. Еще часть удалена совсем.\n",
    "\n",
    "Здесь все еще хламовник, но я пытался хоть немного структурировать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574150c2",
   "metadata": {},
   "source": [
    "## <left>Описание данных\n",
    "\n",
    "Файлы:\n",
    "\n",
    "- `sample_submission.csv`: пример файла-посылки\n",
    "- `train_raw_data.jsonl`, `test_raw_data.jsonl`: \"сырые\" данные \n",
    "- `train_data.csv`, `test_data.csv`: признаки, созданные авторами\n",
    "- `train_targets.csv`: результаты тренировочных игр\n",
    "\n",
    "## <left>Описание признаков\n",
    "    \n",
    "Набор простых признаков, описывающих игроков и команды в целом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9901aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"/kaggle/input/bi-ml-competition-2023/\"\n",
    "\n",
    "df_train_features = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                             \"train_data.csv\"), \n",
    "                                    index_col=\"match_id_hash\")\n",
    "df_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                            \"train_targets.csv\"), \n",
    "                                   index_col=\"match_id_hash\")\n",
    "\n",
    "df_train_features.shape\n",
    "\n",
    "df_train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e71d70",
   "metadata": {},
   "source": [
    "Имеем ~32 тысячи наблюдений, каждое из которых характеризуется уникальным `match_id_hash` (захэшированное id матча), и 245 признаков. `game_time` показывает момент времени, в который получены эти данные. То есть по сути это не длительность самого матча, а например, его середина, таким образом, в итоге мы сможем получить модель, которая будет предсказывать вероятность победы каждой из команд в течение матча (хорошо подходит для букмекеров).\n",
    "\n",
    "Нас интересует поле `radiant_win` (так называется одна из команд, вторая - dire). Остальные колоки здесь по сути получены из \"будущего\" и есть только для тренировочных данных, поэтому на них можно просто посмотреть)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee306ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618efd3a",
   "metadata": {},
   "source": [
    "## <left>Наша первая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_features.values\n",
    "y = df_train_targets[\"radiant_win\"].values.astype(\"int8\")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=0.3, \n",
    "                                                      random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e04d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Обучим случайный лес\n",
    "\n",
    "# %%time\n",
    "# rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "#### Сделаем предсказания и оценим качество на отложенной части данных\n",
    "\n",
    "# y_pred = rf_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "# valid_score = roc_auc_score(y_valid, y_pred)\n",
    "# print(\"ROC-AUC score на отложенной части:\", valid_score)\n",
    "\n",
    "Посмотрим на accuracy:\n",
    "\n",
    "# valid_accuracy = accuracy_score(y_valid, y_pred > 0.5)\n",
    "# print(\"Accuracy score (p > 0.5) на отложенной части:\", valid_accuracy)\n",
    "\n",
    "## <left>Посылка\n",
    "\n",
    "# df_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, \"test_data.csv\"), \n",
    "#                                    index_col=\"match_id_hash\")\n",
    "\n",
    "# X_test = df_test_features.values\n",
    "# y_test_pred = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# df_submission = pd.DataFrame({\"radiant_win_prob\": y_test_pred}, \n",
    "#                                  index=df_test_features.index)\n",
    "\n",
    "# submission_filename = \"submission_{}.csv\".format(\n",
    "#     datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "# df_submission.to_csv(submission_filename)\n",
    "# print(\"Файл посылки сохранен, как: {}\".format(submission_filename))\n",
    "\n",
    "## <left>Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddad63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Во многих случаях кросс-валидация оказывается лучше простого разбиения на test и train. Воспользуемся `ShuffleSplit` чтобы создать 5 70%/30% наборов данных.\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2901772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X, y, cv=cv, scoring=\"roc_auc\")\n",
    "\n",
    "# cv_scores_rf\n",
    "\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ec44c",
   "metadata": {},
   "source": [
    "## <left>Что есть в json файлах?\n",
    "Описание сырых данных можно найти в `train_matches.jsonl` и `test_matches.jsonl`. Каждый файл содержит одну запись для каждого матча в [JSON](https://en.wikipedia.org/wiki/JSON) формате. Его легко превратить в питоновский объект при помощи метода `json.loads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53254155",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, \"train_raw_data.jsonl\")) as fin:\n",
    "    # прочтем 419 строку\n",
    "    for i in range(19):\n",
    "        line = fin.readline()\n",
    "    # переведем JSON в питоновский словарь \n",
    "    match = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Демонстрация определния типа героя. В дальнейшем не использовалась.\n",
    "for i in range(10):\n",
    "    print(match[\"players\"][i][\"hero_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80fe695",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDA - может быть неплохим признаком, этот показатель считается как:\n",
    "    \n",
    "<center>$KDA = \\frac{K + A}{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "player[\"ability_uses\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10f47c",
   "metadata": {},
   "source": [
    "Информация о количестве использованных способностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a9667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(player[\"ability_uses\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb44d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "match[\"players\"][4][\"hero_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44331cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, player in enumerate(match[\"players\"]):\n",
    "    plt.plot(player[\"times\"], player[\"xp_t\"], label=str(i+1))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time, s\")\n",
    "plt.ylabel(\"XP\")\n",
    "plt.title(\"XP change for all players\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7daf00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Сделаем чтение файла с сырыми данными и добавление новых признаков удобным\n",
    "\n",
    "В этот раз для чтение `json` файлов лучше использовать библиотеку `ujson`, иначе все будет слишком долго :(\n",
    "\n",
    "import ujson as json\n",
    "from tqdm.notebook import tqdm\n",
    "    \n",
    "def read_matches(matches_file, total_matches=31698, n_matches_to_read=None):\n",
    "    \"\"\"\n",
    "    Аргуент\n",
    "    -------\n",
    "    matches_file: JSON файл с сырыми данными\n",
    "    \n",
    "    Результат\n",
    "    ---------\n",
    "    Возвращает записи о каждом матче\n",
    "    \"\"\"\n",
    "    \n",
    "    if n_matches_to_read is None:\n",
    "        n_matches_to_read = total_matches\n",
    "        \n",
    "    c = 0\n",
    "    with open(matches_file) as fin:\n",
    "        for line in tqdm(fin, total=total_matches):\n",
    "            if c >= n_matches_to_read:\n",
    "                break\n",
    "            else:\n",
    "                c += 1\n",
    "                yield json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3edf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Чтение данных в цикле\n",
    "\n",
    "Чтение всех данных занимает 1-2 минуты, поэтому для начала можно попробовать следующее:\n",
    "\n",
    "1. Читать 10-50 игр\n",
    "2. Написать код для работы с этими JSON объектами\n",
    "3. Убедиться, что все работает\n",
    "4. Запустить код на всем датасете\n",
    "5. Сохранить результат в `pickle` файл, чтобы в следующий раз не переделывать все заново"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42bf5f4",
   "metadata": {},
   "source": [
    "## <left>Feature engineering\n",
    "\n",
    "Напишем функцию, которая поможет нам легче добавлять новые признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(df_features, matches_file, n_matches=None):\n",
    "    \"\"\"\n",
    "    Аргуенты\n",
    "    -------\n",
    "    df_features: таблица с данными\n",
    "    matches_file: JSON файл с сырыми данными\n",
    "    \n",
    "    Результат\n",
    "    ---------\n",
    "    Добавляет новые признаки в таблицу\n",
    "    \"\"\"\n",
    "    \n",
    "    for match in read_matches(matches_file, n_matches_to_read=n_matches):\n",
    "        match_id_hash = match['match_id_hash']\n",
    "\n",
    "        # Посчитаем количество разрушенных вышек обеими командами\n",
    "        radiant_tower_kills = 0\n",
    "        dire_tower_kills = 0\n",
    "        for objective in match[\"objectives\"]:\n",
    "            if objective[\"type\"] == \"CHAT_MESSAGE_TOWER_KILL\":\n",
    "                if objective[\"team\"] == 2:\n",
    "                    radiant_tower_kills += 1\n",
    "                if objective[\"team\"] == 3:\n",
    "                    dire_tower_kills += 1\n",
    "\n",
    "        df_features.loc[match_id_hash, \"radiant_tower_kills\"] = radiant_tower_kills\n",
    "        df_features.loc[match_id_hash, \"dire_tower_kills\"] = dire_tower_kills\n",
    "        df_features.loc[match_id_hash, \"diff_tower_kills\"] = radiant_tower_kills - dire_tower_kills\n",
    "        \n",
    "        # ... (/¯◡ ‿ ◡)/¯☆*:・ﾟ добавляем новые признаки ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Скопируем таблицу с признаками\n",
    "# df_train_features_extended = df_train_features.copy()\n",
    "\n",
    "# # Добавим новые\n",
    "# add_new_features(df_train_features_extended, \n",
    "#                  os.path.join(PATH_TO_DATA, \n",
    "#                               \"train_raw_data.jsonl\"))\n",
    "\n",
    "# df_train_features_extended.head()\n",
    "\n",
    "# %%time\n",
    "# cv_scores_base = cross_val_score(rf_model, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "# cv_scores_extended = cross_val_score(rf_model, df_train_features_extended.values, y, \n",
    "#                                      cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "# print(f\"ROC-AUC на кросс-валидации для базовых признаков: {cv_scores_base.mean()}\")\n",
    "# print(f\"ROC-AUC на кросс-валидации для новых признаков: {cv_scores_extended.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Издевательство над данными началось!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650af9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, \"test_data.csv\"), \n",
    "                                   index_col=\"match_id_hash\")\n",
    "\n",
    "X_test = df_test_features.values\n",
    "X = df_train_features\n",
    "y = df_train_targets[\"radiant_win\"].values.astype(\"int8\")\n",
    "\n",
    "len(df_train_features.columns)\n",
    "# На старте (до джейсона) имеем 245 фичей\n",
    "\n",
    "#### 1. Константные признаки# Их нет.\n",
    "\n",
    "# # 1. Поищем констанстные признаки\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# sel = VarianceThreshold(threshold=0)\n",
    "# sel.fit(X)\n",
    "# sum(sel.get_support())\n",
    "# # Их нет.\n",
    "\n",
    "#### 2. Квазиконстантные признакиsum(sel.get_support())\n",
    "\n",
    "\n",
    "# # 1. Поищем квазиконстанстные признаки\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# sel = VarianceThreshold(threshold=0.05)\n",
    "# sel.fit(X)\n",
    "# sum(sel.get_support())\n",
    "# quazi_constants = [x for x in df_train_features.columns if x not in df_train_features.columns[sel.get_support()]]\n",
    "# quazi_constants\n",
    "# # Посмотрим внимательнее на количество убийств Рошанов, возможно, стоит удалить эти данные.\n",
    "\n",
    "# for qc in quazi_constants:\n",
    "#     print(sum(df_train_features[qc]))\n",
    "# Видно, что событие достаточно редкое (встречается около 900 раз на 32000 объектов). \n",
    "# Попробуем удалить данные и сравнить скор.\n",
    "\n",
    "# # Удаляем\n",
    "# X_train_new = sel.transform(X)\n",
    "# X_test_new = sel.transform(X_test)\n",
    "# # Проверяем\n",
    "# rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_train_new, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")\n",
    "# # Кросс-валидация стала хуже\n",
    "\n",
    "#### 3. Любуемся на признаки.\n",
    "\n",
    "# Посмотрим на все признаки, попробуем разобраться.\n",
    "# [f\"Переменная -- {column}, количество уровней -- {len(set(df_train_features[column].values))}\" for column in df_train_features.columns]\n",
    "\n",
    "# set(df_train_features[\"lobby_type\"].values)\n",
    "# Лобби принимает строго 2 значения. Метаинформация и кандидат на удаление?\n",
    "# У показателей XP, маны, времени оглушения, золота и здоровья большое число значений. \n",
    "# Возможно, стоит квантильно бинировать эти переменные, чтобы избавиться от шума.\n",
    "\n",
    "# # Избавимся от лобби\n",
    "# X_new = df_train_features.drop(labels=[\"lobby_type\"], axis=1)\n",
    "# print(X_new.shape)\n",
    "# # Проверяем\n",
    "# rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")\n",
    "# # Стало Лучше на одну сотую процента. Ура, бэйзлайн перебит!\n",
    "\n",
    "#### 4. Биннинг, недоделан\n",
    "\n",
    "# Бининг\n",
    "\n",
    "#### 5. Ищем и убираем скоррелированные переменные.\n",
    "\n",
    "# corr_matrix = df_train_features.corr()\n",
    "# # Делать хитмэп на такой куче данных -- гиблое дело. Поэтому будем парсить матрицу корреляции.\n",
    "# corr_matrix\n",
    "\n",
    "# # Очень кривой вариант, надо будет оптимизировать\n",
    "# lab = corr_matrix.columns\n",
    "# for row in lab:\n",
    "#     for col in lab:\n",
    "#         if corr_matrix.loc[row, col] >= 0.95 and row != col:\n",
    "#             print(row, col, corr_matrix.loc[row, col])\n",
    "# # Сильно скоррелированы XP и уровень (логично) и XP и золото (наверное, тоже логично, хотя корреляция прям архи-сильная)\n",
    "# # Уберем XP\n",
    "\n",
    "# # Избавимся от лобби\n",
    "# X_new2 = df_train_features.drop(labels=[\"lobby_type\", \"r1_xp\", \"r2_xp\", \"r3_xp\", \"r4_xp\", \"r5_xp\", \"d1_xp\", \"d2_xp\", \"d3_xp\", \"d4_xp\", \"d5_xp\"], axis=1)\n",
    "# print(X_new.shape)\n",
    "# # Проверяем\n",
    "# rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")\n",
    "# # Стало хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 6. Команда -- больше, чем сумма игроков, ее составляющая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e722cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дропанье можно оптимизировать, но пока и так сойдет   (P.S. Руки так и не дошли. Это, увы, не последний кривой код в ноутбуке.)\n",
    "import re\n",
    "step, finish  = 50, len(df_train_features.columns)\n",
    "actions = [\"kills\", \"deaths\", \"assists\", \"denies\", \"gold\", \"lh\", \"xp\", \"health\", \n",
    "           \"max_health\", \"max_mana\", \"level\", \"stuns\", \"creeps_stacked\", \"camps_stacked\",\n",
    "           \"rune_pickups\", \"firstblood_claimed\", \"teamfight_participation\", \n",
    "           \"towers_killed\", \"roshans_killed\", \"sen_placed\", \"obs_placed\"]\n",
    "commands = [\"r\", \"d\"]\n",
    "X_new = df_train_features.copy()\n",
    "for command in commands:\n",
    "    for action in actions:\n",
    "        start, stop, res = 0, 50, []\n",
    "        regex = f\"{command}\\d_{action}\"\n",
    "        while stop <= finish:\n",
    "            res1 = re.findall(regex, str(df_train_features.columns[start:stop]))\n",
    "            if len(res1) > 0:\n",
    "                res += res1\n",
    "            if stop == finish:\n",
    "                stop += 1\n",
    "            else:\n",
    "                if stop + 50 > finish:\n",
    "                    stop = finish\n",
    "                    start += 50\n",
    "                else:\n",
    "                    stop += 50\n",
    "                    start += 50\n",
    "        var_sum = f\"{command}_{action}_sum\"\n",
    "        var_mean = f\"{command}_{action}_mean\"\n",
    "        res_sum = df_train_features.filter(regex=f\"{command}\\d_{action}\").sum(axis=1)\n",
    "        res_mean = df_train_features.filter(regex=f\"{command}\\d_{action}\").mean(axis=1)\n",
    "        X_new[var_sum] = res_sum\n",
    "        X_new[var_mean] = res_mean\n",
    "        X_new.drop(labels=res, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "step, finish  = 50, len(df_test_features.columns)\n",
    "actions = [\"kills\", \"deaths\", \"assists\", \"denies\", \"gold\", \"lh\", \"xp\", \"health\", \n",
    "           \"max_health\", \"max_mana\", \"level\", \"stuns\", \"creeps_stacked\", \"camps_stacked\",\n",
    "           \"rune_pickups\", \"firstblood_claimed\", \"teamfight_participation\", \n",
    "           \"towers_killed\", \"roshans_killed\", \"sen_placed\", \"obs_placed\"]\n",
    "commands = [\"r\", \"d\"]\n",
    "X_test_new = df_test_features.copy()\n",
    "for command in commands:\n",
    "    for action in actions:\n",
    "        start, stop, res = 0, 50, []\n",
    "        regex = f\"{command}\\d_{action}\"\n",
    "        while stop <= finish:\n",
    "            res1 = re.findall(regex, str(df_test_features.columns[start:stop]))\n",
    "            if len(res1) > 0:\n",
    "                res += res1\n",
    "            if stop == finish:\n",
    "                stop += 1\n",
    "            else:\n",
    "                if stop + 50 > finish:\n",
    "                    stop = finish\n",
    "                    start += 50\n",
    "                else:\n",
    "                    stop += 50\n",
    "                    start += 50\n",
    "        var_sum = f\"{command}_{action}_sum\"\n",
    "        var_mean = f\"{command}_{action}_mean\"\n",
    "        res_sum = df_test_features.filter(regex=f\"{command}\\d_{action}\").sum(axis=1)\n",
    "        res_mean = df_test_features.filter(regex=f\"{command}\\d_{action}\").mean(axis=1)\n",
    "        X_test_new[var_sum] = res_sum\n",
    "        X_test_new[var_mean] = res_mean\n",
    "        X_test_new.drop(labels=res, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важное примечание: здесь и далее вывод скора разных моделей на кросс-валидации закомментирован, чтобы быстрее проконягться на каггле.\n",
    "for_drop_mean = X_new.filter(regex=r\".+mean\").columns\n",
    "for_drop_sum = X_new.filter(regex=r\".+sum\").columns\n",
    "X_new_1 = X_new.drop(labels=for_drop_mean, axis=1)\n",
    "X_new_2 = X_new.drop(labels=for_drop_sum, axis=1)\n",
    "rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_1, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")\n",
    "rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_drop_mean = X_test_new.filter(regex=r\".+mean\").columns\n",
    "for_drop_sum = X_test_new.filter(regex=r\".+sum\").columns\n",
    "X_test_new_1 = X_test_new.drop(labels=for_drop_mean, axis=1)\n",
    "X_test_new_2 = X_test_new.drop(labels=for_drop_sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc159751",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 6.2 Поработаем с этим датасетом дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9aab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 6.2.1 Уберем лобби"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009728c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Избавимся от лобби\n",
    "# X_new = X_new_2.drop(labels=[\"lobby_type\"], axis=1)\n",
    "# print(X_new.shape)\n",
    "# # Проверяем\n",
    "# rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")\n",
    "# # Стало чуть хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eabbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 6.2.2 Выберем k лучших фичей\n",
    "\n",
    "# from sklearn.feature_selection import SelectPercentile, chi2\n",
    "# X_new = df_train_features.copy()\n",
    "# X_new = SelectPercentile(percentile=20).fit_transform(X_new_2, y)\n",
    "# X_new.shape\n",
    "# # Осталось 15 фичей. Запустим лес.# Проверяем\n",
    "# rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877497ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 6.3 Увеличим лес и углубим деревья\n",
    "\n",
    "for_drop_mean = X_new.filter(regex=r\".+mean\").columns\n",
    "for_drop_sum = X_new.filter(regex=r\".+sum\").columns\n",
    "X_new_1 = X_new.drop(labels=for_drop_mean, axis=1)\n",
    "X_new_2 = X_new.drop(labels=for_drop_sum, axis=1)\n",
    "rf_model = RandomForestClassifier(n_estimators=500, max_depth=10, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_1, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")\n",
    "rf_model = RandomForestClassifier(n_estimators=500, max_depth=10, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")\n",
    "# Скор для среднего подрос еще на процент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409f9b0",
   "metadata": {},
   "source": [
    "Поиграем еще. Будем увеличивать отдельно глубину и количество деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наращиваем глубину\n",
    "# depth = [5, 7, 10, 12, 15, 17, 20]\n",
    "# for dep in depth:\n",
    "#     rf_model = RandomForestClassifier(n_estimators=500, max_depth=dep, n_jobs=-1, random_state=SEED)\n",
    "#     cv_scores_rf = cross_val_score(rf_model, X_new_1, y, cv=cv, scoring=\"roc_auc\")\n",
    "#     print(f\"Среднее значение ROC-AUC для суммы по команде на кросс-валидации с глубиной дерева {dep}: {cv_scores_rf.mean()}\")\n",
    "#     rf_model = RandomForestClassifier(n_estimators=500, max_depth=dep, n_jobs=-1, random_state=SEED)\n",
    "#     cv_scores_rf = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "#     print(f\"Среднее значение ROC-AUC для среднего по команде на кросс-валидации с глубиной дерева {dep}: {cv_scores_rf.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "На глубине 15 уже было вполне неплохо, дальше рост был меньше 3 десятых процента\n",
    "\n",
    "# # Наращиваем количество дереьвев\n",
    "# trees_number = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "# for tree_number in trees_number:\n",
    "#     rf_model = RandomForestClassifier(n_estimators=tree_number, max_depth=15, n_jobs=-1, random_state=SEED)\n",
    "#     cv_scores_rf = cross_val_score(rf_model, X_new_1, y, cv=cv, scoring=\"roc_auc\")\n",
    "#     print(f\"Среднее значение ROC-AUC для суммы по команде на кросс-валидации с {tree_number} деревьями в лесу: {cv_scores_rf.mean()}\")\n",
    "#     rf_model = RandomForestClassifier(n_estimators=tree_number, max_depth=15, n_jobs=-1, random_state=SEED)\n",
    "#     cv_scores_rf = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "#     print(f\"Среднее значение ROC-AUC для среднего по команде на кросс-валидации с {tree_number} деревьями в лесу: {cv_scores_rf.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539276b1",
   "metadata": {},
   "source": [
    "Выкрутим на максимум гиперпараметры и сравним с приемлемым вариантом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = RandomForestClassifier(n_estimators=400, max_depth=15, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC для среднего по команде на кросс-валидации с глубиной дерева 15 и 400 деревьями в лесу: {cv_scores_rf.mean()}\")\n",
    "# rf_model = RandomForestClassifier(n_estimators=900, max_depth=20, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC для среднего по команде на кросс-валидации с глубиной дерева 20 и 900 деревьями в лесу: {cv_scores_rf.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc578058",
   "metadata": {},
   "source": [
    "Если мне не будет хватать двух десятых процента, чтобы кого-нибудь обогнать в таблице, я знаю, куда идти. А пока будем использовать 15, 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a98ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 6.4 Схлопнем KDA\n",
    "\n",
    "X_new = X_new_2.copy()\n",
    "X_new[\"r_kda_mean\"] = (X_new_2.r_kills_mean + X_new_2.r_assists_mean)/(X_new_2.r_deaths_mean + 1)\n",
    "X_new[\"d_kda_mean\"] = (X_new_2.d_kills_mean + X_new_2.d_assists_mean)/(X_new_2.d_deaths_mean + 1)\n",
    "X_new.drop(labels=[\"r_kills_mean\", \"r_assists_mean\", \"r_deaths_mean\", \n",
    "                   \"d_kills_mean\", \"d_assists_mean\", \"d_deaths_mean\"], axis=1, inplace=True)\n",
    "rf_model = RandomForestClassifier(n_estimators=400, max_depth=15, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC для среднего по команде на кросс-валидации с kda: {cv_scores_rf.mean()}\")\n",
    "# Капельку лучше\n",
    "\n",
    "X_test_new = X_test_new_2.copy()\n",
    "X_test_new[\"r_kda_mean\"] = (X_test_new_2.r_kills_mean + X_test_new_2.r_assists_mean)/(X_test_new_2.r_deaths_mean + 1)\n",
    "X_test_new[\"d_kda_mean\"] = (X_test_new_2.d_kills_mean + X_test_new_2.d_assists_mean)/(X_test_new_2.d_deaths_mean + 1)\n",
    "X_test_new.drop(labels=[\"r_kills_mean\", \"r_assists_mean\", \"r_deaths_mean\", \n",
    "                   \"d_kills_mean\", \"d_assists_mean\", \"d_deaths_mean\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 7. Уберем координаты\n",
    "\n",
    "# # Избавимся от лобби и координат\n",
    "# X_new = df_train_features.drop(labels=[\"lobby_type\", \"r1_x\", \"r1_y\", \n",
    "#                                       \"r2_x\", \"r2_y\", \n",
    "#                                       \"r3_x\", \"r3_y\", \n",
    "#                                       \"r4_x\", \"r4_y\", \n",
    "#                                       \"r5_x\", \"r5_y\", \n",
    "#                                       \"d1_x\", \"d1_y\", \n",
    "#                                       \"d2_x\", \"d2_y\", \n",
    "#                                       \"d3_x\", \"d3_y\", \n",
    "#                                       \"d4_x\", \"d4_y\", \n",
    "#                                       \"d5_x\", \"d5_y\", ], axis=1)\n",
    "# print(X_new.shape)\n",
    "# # Проверяем\n",
    "# rf_model = RandomForestClassifier(n_estimators=300, max_depth=7, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")\n",
    "# # Стало хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 8. Добавим новые фичи (сначала запустить код ниже!)\n",
    "\n",
    "##### 8.1 Сначала базовую из ноутбука\n",
    "\n",
    "def add_new_features(df_features, matches_file, n_matches=None):\n",
    "    \"\"\"\n",
    "    Аргуенты\n",
    "    -------\n",
    "    df_features: таблица с данными\n",
    "    matches_file: JSON файл с сырыми данными\n",
    "    \n",
    "    Результат\n",
    "    ---------\n",
    "    Добавляет новые признаки в таблицу\n",
    "    \"\"\"\n",
    "    \n",
    "    for match in read_matches(matches_file, n_matches_to_read=n_matches):\n",
    "        match_id_hash = match['match_id_hash']\n",
    "\n",
    "        # Посчитаем количество разрушенных вышек обеими командами\n",
    "        radiant_tower_kills = 0\n",
    "        dire_tower_kills = 0\n",
    "        for objective in match[\"objectives\"]:\n",
    "            if objective[\"type\"] == \"CHAT_MESSAGE_TOWER_KILL\":\n",
    "                if objective[\"team\"] == 2:\n",
    "                    radiant_tower_kills += 1\n",
    "                if objective[\"team\"] == 3:\n",
    "                    dire_tower_kills += 1\n",
    "\n",
    "        df_features.loc[match_id_hash, \"radiant_tower_kills\"] = radiant_tower_kills\n",
    "        df_features.loc[match_id_hash, \"dire_tower_kills\"] = dire_tower_kills\n",
    "        df_features.loc[match_id_hash, \"diff_tower_kills\"] = radiant_tower_kills - dire_tower_kills\n",
    "\n",
    "# Скопируем таблицу с признаками\n",
    "X_new_2_ext = X_new_2.copy()\n",
    "\n",
    "# Добавим новые\n",
    "add_new_features(X_new_2_ext, \n",
    "                 os.path.join(PATH_TO_DATA, \n",
    "                              \"train_raw_data.jsonl\"))\n",
    "\n",
    "# Скопируем таблицу с признаками\n",
    "X_test_new_2_ext = X_test_new_2.copy()\n",
    "\n",
    "# Добавим новые\n",
    "add_new_features(X_test_new_2_ext, \n",
    "                 os.path.join(PATH_TO_DATA, \n",
    "                              \"test_raw_data.jsonl\"), n_matches=7977)\n",
    "\n",
    "# cv_scores_base = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "# cv_scores_extended = cross_val_score(rf_model, X_new_2_ext, y, \n",
    "#                                      cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "# print(f\"ROC-AUC на кросс-валидации для базовых признаков: {cv_scores_base.mean()}\")\n",
    "# print(f\"ROC-AUC на кросс-валидации для новых признаков: {cv_scores_extended.mean()}\")\n",
    "# На одну десятую процента лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6852d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 9. Ансамбли\n",
    "\n",
    "# import xgboost\n",
    "# import lightgbm\n",
    "# import catboost\n",
    "# from sklearn.ensemble import (ExtraTreesClassifier,\n",
    "#                               VotingClassifier)\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# # rf_model из шага с итоговым скором (дальше)\n",
    "# etc = ExtraTreesClassifier(random_state=SEED)\n",
    "# knn = KNeighborsClassifier(n_neighbors=5, weights=\"distance\")\n",
    "# svc_lin = SVC(kernel='linear', probability=True, random_state=SEED)\n",
    "# svc_rbf = SVC(kernel='rbf', probability=True, random_state=SEED)\n",
    "# cat = catboost.CatBoostClassifier(verbose=0, random_seed=SEED)\n",
    "# lgbm = lightgbm.LGBMClassifier(random_state=SEED)\n",
    "# lgbm_rf = lightgbm.LGBMClassifier(boosting_type=\"rf\", bagging_freq=1, bagging_fraction=0.7, random_state=SEED)\n",
    "# xgb = xgboost.XGBClassifier(random_state=SEED)\n",
    "# xgb_rf = xgboost.XGBRFClassifier(random_state=SEED)\n",
    "# lr = LogisticRegression(solver='liblinear', max_iter=10000)\n",
    "# nb = GaussianNB()\n",
    "# new_1_models = [(\"RF\", rf_model), \n",
    "#                (\"ETC\", etc), (\"KNN\", knn), \n",
    "#                (\"SVC_LIN\", svc_lin), (\"SVC_RBF\", svc_rbf), \n",
    "#                (\"CAT\", cat),\n",
    "#                (\"LGBM_RF\", lgbm_rf), (\"XGB\", xgb), \n",
    "#                (\"XGB_RF\", xgb_rf), (\"LR\", lr), (\"NB\", nb)]\n",
    "# voting_hard = VotingClassifier(new_1_models, voting='hard')\n",
    "# voting_soft = VotingClassifier(new_1_models, voting='soft')\n",
    "\n",
    "# for model in [rf_model, cat, etc, knn, svc_lin, svc_rbf, xgb, lgbm, xgb_rf, lgbm_rf, lr, nb, voting_hard, voting_soft]: \n",
    "#     scores = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "#     print(f\"{model.__class__.__name__}: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 10. Работа с категориальными переменными\n",
    "\n",
    "# [f\"Переменная -- {column}, количество уровней -- {len(set(X_new_2_ext[column].values))}\" for column in X_new_2_ext.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dcfff4",
   "metadata": {},
   "source": [
    "# Итоговый скор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c339f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=400, max_depth=15, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC для среднего по команде на кросс-валидации глубина 15 и 400 деревьев: {cv_scores_rf.mean()}\")\n",
    "\n",
    "# Много и глубоко\n",
    "rf_model = RandomForestClassifier(n_estimators=900, max_depth=20, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC для среднего по команде на кросс-валидации глубина 20 и 900 деревьев: {cv_scores_rf.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDA\n",
    "X_new_2_kda = X_new_2.copy()\n",
    "X_new_2_kda[\"r_kda_mean\"] = (X_new_2.r_kills_mean + X_new_2.r_assists_mean)/(X_new_2.r_deaths_mean + 1)\n",
    "X_new_2_kda[\"d_kda_mean\"] = (X_new_2.d_kills_mean + X_new_2.d_assists_mean)/(X_new_2.d_deaths_mean + 1)\n",
    "X_new_2_kda.drop(labels=[\"r_kills_mean\", \"r_assists_mean\", \"r_deaths_mean\", \n",
    "                   \"d_kills_mean\", \"d_assists_mean\", \"d_deaths_mean\"], axis=1, inplace=True)\n",
    "# rf_model = RandomForestClassifier(n_estimators=900, max_depth=20, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_2_kda, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC для среднего по команде на кросс-валидации глубина 20 и 900 деревьев: {cv_scores_rf.mean()}\")\n",
    "\n",
    "X_test_new_2_kda = X_test_new_2.copy()\n",
    "X_test_new_2_kda[\"r_kda_mean\"] = (X_test_new_2.r_kills_mean + X_test_new_2.r_assists_mean)/(X_test_new_2.r_deaths_mean + 1)\n",
    "X_test_new_2_kda[\"d_kda_mean\"] = (X_test_new_2.d_kills_mean + X_test_new_2.d_assists_mean)/(X_test_new_2.d_deaths_mean + 1)\n",
    "X_test_new_2_kda.drop(labels=[\"r_kills_mean\", \"r_assists_mean\", \"r_deaths_mean\", \n",
    "                   \"d_kills_mean\", \"d_assists_mean\", \"d_deaths_mean\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(df_features, matches_file, n_matches=None):\n",
    "    \"\"\"\n",
    "    Аргуенты\n",
    "    -------\n",
    "    df_features: таблица с данными\n",
    "    matches_file: JSON файл с сырыми данными\n",
    "    \n",
    "    Результат\n",
    "    ---------\n",
    "    Добавляет новые признаки в таблицу\n",
    "    \"\"\"\n",
    "    \n",
    "    for match in read_matches(matches_file, n_matches_to_read=n_matches):\n",
    "        match_id_hash = match['match_id_hash']\n",
    "\n",
    "        radiant_barracks_kills = 0\n",
    "        dire_barracks_kills = 0         \n",
    "        radiant_tower_kills = 0\n",
    "        dire_tower_kills = 0\n",
    "        r_aegis = 0\n",
    "        d_aegis = 0\n",
    "        \n",
    "        for objective in match[\"objectives\"]:\n",
    "            if objective[\"type\"] == \"CHAT_MESSAGE_TOWER_KILL\":\n",
    "                if objective[\"team\"] == 2:\n",
    "                    radiant_tower_kills += 1\n",
    "                if objective[\"team\"] == 3:\n",
    "                    dire_tower_kills += 1\n",
    "            if objective[\"type\"] == \"CHAT_MESSAGE_AEGIS\":\n",
    "                if objective['player_slot'] < 100:\n",
    "                    r_aegis += 1\n",
    "                if objective[\"player_slot\"] > 100:\n",
    "                    d_aegis += 1\n",
    "\n",
    "        # Посмторим, кто разрушил последнюю вышку в игре\n",
    "        objs = match['objectives'][::-1]\n",
    "        for objective in objs:\n",
    "            if objective[\"type\"] == \"CHAT_MESSAGE_TOWER_KILL\":\n",
    "                if objective[\"team\"] == 2:\n",
    "                    last_tower_kill = 2\n",
    "                if objective[\"team\"] == 3:\n",
    "                    last_tower_kill = 0\n",
    "                break\n",
    "            else:\n",
    "                last_tower_kill = 1\n",
    "                \n",
    "        for i, mess in enumerate(objs):\n",
    "            if mess['type'] == 'CHAT_MESSAGE_BARRACKS_KILL':\n",
    "                for message in objs[i + 1:]:\n",
    "                    if \"slot\" in message.keys():\n",
    "                        if message['slot'] < 100:\n",
    "                            radiant_barracks_kills += 1\n",
    "                        if message['slot'] > 100:\n",
    "                            dire_barracks_kills += 1\n",
    "                        break\n",
    "\n",
    "        df_features.loc[match_id_hash, \"radiant_barracks_kills\"] = radiant_barracks_kills\n",
    "        df_features.loc[match_id_hash, \"dire_barracks_kills\"] = dire_barracks_kills\n",
    "        df_features.loc[match_id_hash, \"diff_barack_kills\"] = radiant_barracks_kills - dire_barracks_kills\n",
    "        df_features.loc[match_id_hash, \"last_tower_kill\"] = last_tower_kill\n",
    "        df_features.loc[match_id_hash, \"r_aegis_mean\"] = r_aegis / 5\n",
    "        df_features.loc[match_id_hash, \"d_aegis_mean\"] = d_aegis / 5\n",
    "        df_features.loc[match_id_hash, \"radiant_tower_kills\"] = radiant_tower_kills\n",
    "        df_features.loc[match_id_hash, \"dire_tower_kills\"] = dire_tower_kills\n",
    "        df_features.loc[match_id_hash, \"diff_tower_kills\"] = radiant_tower_kills - dire_tower_kills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16676c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скопируем таблицу с признаками\n",
    "X_new_2_ext = X_new_2_kda.copy()\n",
    "\n",
    "# Добавим новые\n",
    "add_new_features(X_new_2_ext, \n",
    "                 os.path.join(PATH_TO_DATA, \n",
    "                              \"train_raw_data.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new_2_ext = X_test_new_2_kda.copy()\n",
    "\n",
    "# Добавим новые\n",
    "add_new_features(X_test_new_2_ext, \n",
    "                 os.path.join(PATH_TO_DATA, \n",
    "                              \"test_raw_data.jsonl\"), n_matches=7977)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(df_features, matches_file, n_matches=None):\n",
    "    \"\"\"\n",
    "    Аргуенты\n",
    "    -------\n",
    "    df_features: таблица с данными\n",
    "    matches_file: JSON файл с сырыми данными\n",
    "    \n",
    "    Результат\n",
    "    ---------\n",
    "    Добавляет новые признаки в таблицу\n",
    "    \"\"\"\n",
    "    \n",
    "    for match in read_matches(matches_file, n_matches_to_read=n_matches):\n",
    "        match_id_hash = match['match_id_hash']\n",
    "\n",
    "        # Посчитаем количество разрушенных вышек обеими командами\n",
    "        r_used_abilities = 0\n",
    "        d_used_abilities = 0\n",
    "        r_xp_2mean = 0\n",
    "        d_xp_2mean = 0\n",
    "        for i in range (4):\n",
    "            r_used_abilities += sum(match[\"players\"][i][\"ability_uses\"].values())\n",
    "            if len(match['players'][i]['xp_t']) != 0:\n",
    "                r_xp_2mean += round(np.mean(match['players'][i]['xp_t']),2)\n",
    "        for i in range(5,10):\n",
    "            d_used_abilities += sum(match[\"players\"][i][\"ability_uses\"].values())\n",
    "            if len(match['players'][i]['xp_t']) != 0:\n",
    "                d_xp_2mean += round(np.mean(match['players'][i]['xp_t']),2)\n",
    "\n",
    "        df_features.loc[match_id_hash, \"r_used_abilities_mean\"] = r_used_abilities / 5\n",
    "        df_features.loc[match_id_hash, \"d_used_abilities_mean\"] = d_used_abilities / 5\n",
    "        df_features.loc[match_id_hash, \"diff_used_abilities\"] = r_used_abilities - d_used_abilities           \n",
    "        df_features.loc[match_id_hash, \"r_xp_2mean\"] = r_xp_2mean / 5\n",
    "        df_features.loc[match_id_hash, \"d_xp_2mean\"] = d_xp_2mean / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c99c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_new_2_ext.copy()\n",
    "\n",
    "# Добавим новые\n",
    "add_new_features(X_new, \n",
    "                 os.path.join(PATH_TO_DATA, \n",
    "                              \"train_raw_data.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = X_test_new_2_ext.copy()\n",
    "\n",
    "# Добавим новые\n",
    "add_new_features(X_test_new, \n",
    "                 os.path.join(PATH_TO_DATA, \n",
    "                              \"test_raw_data.jsonl\"), n_matches=7977)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004436a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В удаленных ячейках были безуспешные попытки поднять скор на кросс-вале исключением золота и опыта из числа предикторов. \n",
    "corr = X_new.corr()\n",
    "lab = corr.columns\n",
    "for row in lab:\n",
    "    for col in lab:\n",
    "        if corr.loc[row, col] >= 0.95 and row != col:\n",
    "            print(row, col, corr.loc[row, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec692327",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=900, max_depth=20, n_jobs=-1, random_state=SEED)\n",
    "# cv_scores_rf = cross_val_score(rf_model, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_rf.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72660733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем запустить линрегрессию\n",
    "# Проверим дисбаланс классов\n",
    "np.unique(y, return_counts=True)    # Все отлично"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "# cv_scores_lr = cross_val_score(lr, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_lr.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# vc_hard = VotingClassifier([(\"RF\", rf_model), (\"LR\", lr)], voting='hard') # Падает\n",
    "vc_soft = VotingClassifier([(\"RF\", rf_model), (\"LR\", lr)],  voting='soft')\n",
    "# cv_scores_vh = cross_val_score(vc_hard, X_new, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_vh.mean()}\")\n",
    "# cv_scores_vs = cross_val_score(vc_soft, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_vs.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "X_new_2 = X_new.copy()\n",
    "X_test_new_2 = X_test_new.copy()\n",
    "sp = SelectPercentile(percentile=80)\n",
    "sp.fit(X_new_2, y)\n",
    "X_new_trans = sp.transform(X_new_2)\n",
    "X_test_new_trans = sp.transform(X_test_new_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vc_soft = VotingClassifier([(\"RF\", rf_model), (\"LR\", lr)],  voting='soft')\n",
    "# cv_scores_vs = cross_val_score(vc_soft, X_new_2, y, cv=cv, scoring=\"roc_auc\")\n",
    "# print(f\"Среднее значение ROC-AUC на кросс-валидации: {cv_scores_vs.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Окончательная посылка\n",
    "#rf_model.fit(X_new_2, y)\n",
    "vc_soft.fit(X_new_trans, y)\n",
    "\n",
    "y_test_pred = vc_soft.predict_proba(X_test_new_trans)[:, 1]\n",
    "\n",
    "df_submission = pd.DataFrame({\"radiant_win_prob\": y_test_pred}, \n",
    "                                 index=df_test_features.index)\n",
    "submission_filename = \"submission_{}.csv\".format(\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "df_submission.to_csv(submission_filename)\n",
    "print(\"Файл посылки сохранен, как: {}\".format(submission_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5154d8a",
   "metadata": {},
   "source": [
    "Была еще попытка запустить LGBM на пару с оптюной, но из-за позднего старта и выдезающих отовсюду флотов, идея была отброшена."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
